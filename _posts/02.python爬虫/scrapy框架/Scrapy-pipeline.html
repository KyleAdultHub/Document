---
title: Scrapy-pipeline
date: "2017-03-08 10:00:00"
categories:
- python爬虫
- scrapy框架
tags:
- 爬虫
- scrapy
toc: true
typora-root-url: ..\..\..
---

<html>
<body>
<div>
<span><div><div><span style="background-color: rgb(255, 250, 165); font-size: 14pt; color: rgb(50, 135, 18); font-weight: bold;-evernote-highlight:true;">pipeline的配置</span></div><ul><li><div><span style="font-size: 10pt; font-weight: bold;">pipeline类的作用</span></div></li><ul><li><div><span style="font-size: 9pt;">接收引擎传递过来的数据，对数据进行处理</span></div></li></ul><li><div><span style="font-size: 10pt; font-weight: bold;">配置pipeline类（在pipelines文件中）</span></div></li></ul><div style="box-sizing: border-box; padding: 8px; border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);"><div><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">    class Myspiderpipline(object):</span></div><div><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">        def process_item(self, item, spider):   # </span><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51);">实现数据处理的方法，方法名不能修改</span></div><div><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">            with open('temp.txt', 'a') as f:</span></div><div><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">                json.dump( item, f, ensure_ascii=False, indent=2)</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                        </span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51);"># 将item打印，并</span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51);">将item传递给后面的pipeline，</span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51);">实现数据在管道pipeline之间的传递</span></div><div><span style="background-color: rgb(251, 250, 248);">              </span> <span style="background-color: rgb(251, 250, 248); font-family: &quot;Yu Gothic UI Semilight&quot;;">     return item      </span></div></div><ul><ul><li><div><span style="font-size: 9pt; font-weight: bold;">注意：</span></div></li><li><div><span style="font-size: 9pt;">process_item方法中的spider参数，表示传递参数过来的爬虫对象</span></div></li><li><div><span style="font-size: 9pt;">spider： 传递数据的爬虫对象，spider.name可以返回爬虫的名称</span></div></li><li><div><span style="font-size: 9pt;">item：传递过来的数据</span></div></li></ul><li><div><span style="font-size: 10pt; font-weight: bold;">setting文件中的设置开启pipeline</span></div></li></ul><div style="box-sizing: border-box; padding: 8px; border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);"><div><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">    ITEM_PIPELINE = {</span></div><div><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">        'myspider.pipelines.MyspiderPipeline': 300,</span></div><div><span style="background-color: rgb(251, 250, 248); font-size: 9pt; color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">    }</span></div></div><ul><ul><li><div><span style="font-size: 9pt; font-weight: bold;">注意：</span></div></li><li><div><span style="font-size: 9pt;">'muspider.pipelines.MyspiderPipeline'是pipeline文件的路径</span></div></li><li><div><span style="font-size: 9pt;">300  是pipeline的权重，pipeline的权重越小，其优先级越高，可以理解为距离引擎的远近</span></div></li><li><div><span style="font-size: 9pt;">如果权重相同的两个pipeline，scrapy会自动的将键值进行排序，根据排序结果定义访问顺序</span></div></li></ul><li><div><span style="font-size: 10pt; font-weight: bold;">pipeline的方法</span></div></li></ul><div style="box-sizing: border-box; padding: 8px; font-size: 12px; border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);"><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">      form pymongo import MongoClient   </span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">      class Myspiderpipline(object):</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">      </span> <span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">    </span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;"> </span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: 微软雅黑; font-weight: bold;"># open_spider在爬虫开启请求start_url前的时候只执行一次，一般用于导入数据库</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">             def open_spider(self,  spider):  </span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                    # 实例化一个mongoclient</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                   con = MongoClient(spider.settings.get('HOST'), spider.settings.get('PORT'))</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                   db = con[spider.settings.get('DB')]</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                   self.collection = db[spider.settings.get('COLLECTON')]</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">        </span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;"> </span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">          </span> <span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: 微软雅黑; font-weight: bold;"> </span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: 微软雅黑; font-weight: bold;"># close_spider在爬虫关闭的时候只执行 一次，一般用于需要关闭的数据库关闭</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">            def close_spider(self,  spider):</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                    print('关闭pipeline')</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                  </span> <span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;"> return item      </span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">       <span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco; font-weight: bold;"> </span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco; font-weight: bold;">    # from_crawler连接到setting.py的配置文件</span></span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">            def from_crawler(cls, crawler):</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                    return  cls(mongo_uri=crawler.settings.get('MGONGO_URI'))</span></div></div><ul><li><div><span style="font-size: 10pt; font-weight: bold;">备注：</span></div></li><ul><li><div><span style="font-size: 9pt;">一个项目会有多个spider，不同的pipeline处理不同的item的内容</span></div></li><li><div><span style="font-size: 9pt;">一个spider的内容可能要做不同的操作，比如存入不同的数据库中</span></div></li></ul></ul><div><span style="font-size: 18px; background-color: rgb(255, 250, 165); color: rgb(50, 135, 18); font-weight: bold;-evernote-highlight:true;">pipeline向mongoDB中插入数据</span></div><ul><li><div><span style="font-size: 10pt; font-weight: bold; line-height: 1.45;">在pipeline类的外部定义使用的mongodb集合</span></div></li></ul><div style="box-sizing: border-box; padding: 8px; font-size: 12px; border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);"><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">     from pymongo import MongoClient</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">     client = MongoClient(host='127.0.0.1', port=27017)    </span><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51);"># 实例化mongodb客户端</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">     collection = client['myspider']['yangguang']</span></div></div><ul><li><div><span style="font-size: 10pt; font-weight: bold;">在pipeline类open_spider中导入mongodb</span></div></li></ul><div style="box-sizing: border-box; padding: 8px; font-size: 12px; border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);"><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">    form pymongo import MongoClient   </span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">    class Myspiderpipline(object):</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">     </span> <span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: 微软雅黑;">  # open_spider在爬虫开启的时候只执行一次</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">        def open_spider(self,  spider):  </span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">            # 实例化一个mongoclient</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">            con = MongoClient(spider.settings.get('HOST'), spider.settings.get('PORT'))</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">            db = con[spider.settings.get('DB')]</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace;">            self.collection = db[spider.settings.get('COLLECTON')]</span></div></div><ul><li><div><span style="font-size: 10pt; font-weight: bold;">向集合中插入数据</span></div></li></ul><div style="box-sizing: border-box; padding: 8px; font-size: 12px; border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);"><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">            def process_item(self, item, spider):</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                item['collection_text'] = ****</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                collection.insert(dict(item))   # 向mongodb中插入数据</span></div><div><span style="font-size: 9pt; background-color: rgb(251, 250, 248); color: rgb(51, 51, 51); font-family: Monaco;">                return item</span></div></div><div><ul><li><div><span style="font-size: 10pt; font-weight: bold;">向Mongodb中插入数据</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 15.2px;">要在setting中配置</span></div></li><ul><li><div><span style="font-size: 9pt;">MONGO_URI = '127.0.0.1'</span></div></li><li><div><span style="font-size: 9pt;">MONGO_DATABASE = '数据库名'</span></div></li></ul><li><div><img src="/e_img/Scrapy-pipeline_files/Image.png" type="image/png" data-filename="Image.png" style="font-size: 9pt;" width="434"/></div></li></ul></ul></div></div><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><span style="background-color: rgb(255, 250, 165); font-size: 14pt; color: rgb(50, 135, 18); font-weight: bold;-evernote-highlight:true;">pipeline向Mysql中存入数据</span></span></div><div><ul><li><div><span style="font-size: 10pt; font-weight: bold;">数据同步的方式写入Mysql</span></div></li><ul><li><div><img src="/e_img/Scrapy-pipeline_files/Image [1].png" type="image/png" data-filename="Image.png" style="font-size: 9pt;" width="610"/></div></li></ul><li><div><span style="font-size: 10pt; font-weight: bold;">数据异步的方式写入Mysql</span></div></li><ul><li><div><img src="/e_img/Scrapy-pipeline_files/Image [2].png" type="image/png" data-filename="Image.png" style="font-size: 9pt;" width="562"/></div></li></ul></ul></div><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><span style="background-color: rgb(255, 250, 165); font-size: 14pt; color: rgb(50, 135, 18); font-weight: bold;-evernote-highlight:true;">数据自动导出json文件</span></span></div><div><ul><li><div><font style="font-size: 10pt;"><span style="font-size: 10pt; font-weight: bold; line-height: 21.6px;">自定义形式导出</span></font></div></li><ul><li><div><img src="/e_img/Scrapy-pipeline_files/Image [3].png" type="image/png" data-filename="Image.png" style="font-size: 9pt;" width="357"/></div></li></ul><li><div><font style="font-size: 10pt;"><span style="font-size: 10pt; font-weight: bold;">使用scrapy自带exportor导出</span></font></div></li><ul><li><div><img src="/e_img/Scrapy-pipeline_files/Image [4].png" type="image/png" data-filename="Image.png" style="font-size: 9pt;" width="466"/></div></li></ul></ul></div><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><span style="background-color: rgb(255, 250, 165); font-size: 14pt; color: rgb(50, 135, 18); font-weight: bold;-evernote-highlight:true;">将爬取去到的图片地址对应的图片进行存储</span></span></div><div><ul><li><div><span style="font-size: 10pt; font-weight: bold;">setting文件中设置图片存储位置</span></div></li><ul><li><div><img src="/e_img/Scrapy-pipeline_files/Image [5].png" type="image/png" data-filename="Image.png" style="font-size: 9pt;" width="574"/></div></li></ul><li><div><span style="font-size: 10pt; font-weight: bold;">pipeline中对图片进行下载</span></div></li><ul><li><div><img src="/e_img/Scrapy-pipeline_files/Image [6].png" type="image/png" data-filename="Image.png" style="font-size: 9pt;" width="378"/></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; font-weight: bold;">ArticleImagePipeline类的方法</span></font></div></li><ul><li><div><span style="font-size: 9pt;">get_media_requests(self, item, info)</span></div></li><ul><li><div><span style="font-size: 9pt;">该方法实现将item字段中的url字段取出来，然后直接生成Request对象，请求对象会加入到对列中，等待执行下载</span></div></li></ul><li><div><span style="font-size: 9pt;">file_path(self, request, response=None, info=None)</span></div></li><ul><li><div><span style="font-size: 9pt;">这个方法用来返回保存的文件名</span></div></li></ul><li><div><span style="font-size: 9pt;">item_completed(self, results, item, info)</span></div></li><ul><li><div><span style="font-size: 9pt;">当单个item完成下载后的处理方法</span></div></li><li><div><span style="font-size: 9pt;">results参数就是该item对应的下载结果，它是一个列表形式，列表的每一个元素就是一个元组，其中包含了下载成功或者失败的信息</span></div></li></ul></ul></ul></ul></div><div><br/></div></span>
</div></body></html>