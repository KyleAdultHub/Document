---
title: 自然语言处理的流程
date: "2018-05-22 20:00:00"
categories:
- 机器学习
- 自然语言处理
tags:
- 机器学习
- 自然语言处理
toc: true
typora-root-url: ..\..\..
---

<html>
<body>
<div>
<span><div><font style="font-size: 14pt;"><span style="color: rgb(50, 135, 18); font-size: 14pt; font-weight: bold; background-color: rgb(255, 250, 165);-evernote-highlight:true;">自然语言的文本处理流程</span></font></div><div><ul><li><div><span style="line-height: 1.45;"><font style="font-size: 9pt;">备注：汉语的自然语言处理流程和英语的自然语言处理流程差了一步词形归一化</font></span></div></li><li><div><span style="font-size: 9pt;"><img src="/e_img/自然语言处理的流程_files/Image.png" type="image/png" data-filename="Image.png" style="line-height: 1.45;" width="309"/></span></div></li></ul><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><font style="font-size: 14pt;"><span style="background-color: rgb(255, 250, 165); line-height: 13.6px; color: rgb(50, 135, 18); font-size: 14pt; font-weight: bold;-evernote-highlight:true;">英文文本的处理流程</span></font></span></div><ul><li><div><font style="font-size: 10pt;"><span style="line-height: 1.45; font-size: 10pt; font-weight: bold;">0.语料库的使用（没有实际的作用）--查看语料库的信息</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">使用方法</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">导入语料库，以导入布朗大学语料库为例（brown）</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">nltk</span></div></li><li><div><span style="font-size: 9pt; line-height: 1.45;">from</span> <span style="font-size: 9pt; line-height: 1.45;">nltk.corpus</span> <span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">brown   brown为语料库，需要提前使用下载器进行下载</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">查看语料库包含的类别（没有实际作用）</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">print(brown.categories())</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">查看语料库中包含的句子和单词（没有实际作用）</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">brown.sents()</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">brown.words()</span></div></li></ul></ul></ul><li><div><font style="font-size: 10pt;"><span style="line-height: 13.6px; font-size: 10pt; font-weight: bold;">1.文本分词处理</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">分词的作用</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">将句子拆分成 具有语言语义学上意义的词</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">中、英文分词区别：</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">英文中，单词之间是以空格作为自然分界符的</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">中文中没有一个形式上的分界符，分词比英文复杂的多</span></div></li></ul></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">分词处理的方法</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">导入模块</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">nltk</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">准备需要分词的句子或者文章</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">text =</span> <span style="font-size: 9pt; line-height: 1.45;">&quot;Python is a high-level programming language, and i like it!&quot;</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">对文本进行分句处理（只有当文本太大，需要对每一句话进行处理的时候使用）</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">seg_list = nltk.sent(text)    对文本进行分句，返回有多个句子组成的列表</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">对文本进行分词  (</span><span style="font-size: 9pt; line-height: 1.45;">需要事先安装 punkt 分词模型</span><span style="font-size: 9pt; line-height: 1.45;">)</span></font></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">seg_list = nltk.word_tokenize(text)    对文本进行分词，返回分词后单词组成的列表</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 13.6px;">分词后的结果：</span><span style="font-size: 9pt; line-height: 1.45;">seg_list</span></font></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">['Python', 'is', 'a', 'high-level', 'programming', 'language', '!']</span></div></li></ul></ul></ul><li><div><font style="font-size: 10pt;"><span style="font-size: 10pt; font-weight: bold; line-height: 13.6px;">1.1.词性标注</span><span style="font-size: 10pt; font-weight: bold; line-height: 13.6px;">(Part-Of-Speech)-获取每个单词的词性，</span><span style="font-size: 10pt; font-weight: bold; line-height: 13.6px;">可选步骤</span><span style="font-size: 10pt; font-weight: bold; line-height: 13.6px;">（根据需要使用）</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">词性标注的方法</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">导入模块</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">nltk</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">分词后进行词性标注</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">words = nltk.word_tokenize(</span><span style="font-size: 9pt; line-height: 1.45;">'Python is a widely used programming language.'</span><span style="font-size: 9pt; line-height: 1.45;">)</span></font></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">nltk.pos_tag(words)    </span><span style="font-size: 9pt; line-height: 1.45;">需要下载 averaged_perceptron_tagger</span></font></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">分词后的结果</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">[('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('widely', 'RB'), ('used', 'VBN'), ('programming', 'NN'), ('language', 'NN'), ('.', '.')]、</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">常见的词性</span></div></li><ul><li><div><span style="font-size: 9pt;"><img src="/e_img/自然语言处理的流程_files/Image [1].png" type="image/png" data-filename="Image.png" style="line-height: 1.45;" width="316"/></span></div></li></ul></ul></ul><li><div><font style="font-size: 10pt;"><span style="line-height: 13.6px; font-size: 10pt; font-weight: bold;">2.词形归一化（只有处理英文问本的时候才需要）</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">词形归一的作用</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 13.6px;">类似 look, looked, looking这些不同时态的单词，会</span><span style="font-size: 9pt; line-height: 1.45;">影响语料学习的准确度</span></font></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">通过词形归一化，可以将这些单词转化为同一的单词</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="line-height: 1.45; font-size: 9pt; font-weight: bold;">①词干提取(stemming)</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">作用</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">可以将单词的ing, ed去掉，只保留单词主干</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">NLTK中常用的词干提取工具stemmer：PorterStemmer, SnowballStemmer, LancasterStemmer</span></div></li></ul><li><div><span style="line-height: 1.45; font-size: 9pt;">词干提取的方法</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">PorterStemmer（只支持英语） 的使用方法</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">导入模块</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">from</span> <span style="font-size: 9pt; line-height: 1.45;">nltk.stem.porter</span> <span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">PorterStemmer</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">创建工具对象</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">porter_stemmer = PorterStemmer()</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">对单词进行词干提取</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">porter_stemmer.stem(</span><span style="font-size: 9pt; line-height: 1.45;">'looked'</span><span style="font-size: 9pt; line-height: 1.45;">)      返回进行词干提取后的单词</span></font></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">porter_stemmer.stem(</span><span style="font-size: 9pt; line-height: 1.45;">'looking'</span><span style="font-size: 9pt; line-height: 1.45;">)     <span style="font-size: 9pt; line-height: 1.45;">返回进行词干提取后的单词</span></span></font></div></li></ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 13.6px;">提取后的结果</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">look  look</span></div></li></ul></ul><li><div><span style="line-height: 1.45; font-size: 9pt;">SnowballStemmer（支持多种语言）的使用方法</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">导入模块</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">from</span> <span style="font-size: 9pt; line-height: 1.45;">nltk.stem,snowball</span><span style="font-size: 9pt;"> </span><span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">SnowballStemmer</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">创建工具对象，并选择语言</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">SnowballStemmer.languages     查看支持的语言</span></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">snowball_stemmer = SnowballStemmer(</span><span style="font-size: 9pt; line-height: 1.45;">'english'</span><span style="font-size: 9pt; line-height: 1.45;">)</span></font></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">对单词进行词干提取</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">snowball_stemmer.stem(</span><span style="font-size: 9pt; line-height: 1.45;">'looked'</span><span style="font-size: 9pt; line-height: 1.45;">)     <span style="font-size: 9pt; line-height: 1.45;">返回进行词干提取后的单词</span></span></font></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">snowball_stemmer.stem(</span><span style="font-size: 9pt; line-height: 1.45;">'looking'</span><span style="font-size: 9pt; line-height: 1.45;">))     <span style="font-size: 9pt; line-height: 1.45;">返回进行词干提取后的单词</span></span></font></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">提取后的结果</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">look  look</span></div></li></ul></ul><li><div><span style="line-height: 1.45; font-size: 9pt;">LancasterStemmer（在大文本提取的时候速度更快） 的使用方法</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">导入模块</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">from</span> <span style="font-size: 9pt; line-height: 1.45;">nltk.stem.lancaster</span> <span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">LancasterStemmer</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">创建工具对象</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">lancaster_stemmer = LancasterStemmer()</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">对单词进行词干提取</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">lancaster_stemmer.stem(</span><span style="font-size: 9pt; line-height: 1.45;">'looked'</span><span style="font-size: 9pt; line-height: 1.45;">)     <span style="font-size: 9pt; line-height: 1.45;">返回进行词干提取后的单词</span></span></font></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">lancaster_stemmer.stem(</span><span style="font-size: 9pt; line-height: 1.45;">'looking'</span><span style="font-size: 9pt; line-height: 1.45;">)     <span style="font-size: 9pt; line-height: 1.45;">返回进行词干提取后的单词</span></span></font></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">提取后的结果</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">look  look</span></div></li></ul></ul></ul></ul><li><div><font style="font-size: 9pt;"><span style="line-height: 13.6px; font-size: 9pt; font-weight: bold;">②词形归并(lemmatization)</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">词形归并的作用</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">可以将单词的各种词形归并成一种形式</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">如am, is, are -&gt; be, went-&gt;go，boxes-&gt;box</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">指明词性可以更准确地进行</span><span style="font-size: 9pt; line-height: 13.6px;">词形归并</span></font></div></li></ul><li><div><span style="font-size: 9pt;">词形归并的使用方法：</span><span style="font-size: 9pt; line-height: 1.45;">WordNetLemmatizer</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">导入模块</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">from</span> <span style="font-size: 9pt; line-height: 1.45;">nltk.stem</span> <span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">WordNetLemmatizer</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">创建工具对象</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">wordnet_lematizer = WordNetLemmatizer()    </span><span style="font-size: 9pt; line-height: 1.45;">需要下载wordnet语料库</span></font></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">进单词进行词形归并</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">wordnet_lematizer.lemmatize(</span><span style="font-size: 9pt; line-height: 1.45;">'cats'</span><span style="font-size: 9pt; line-height: 1.45;">))     默认按照名词处理</span></font></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">wordnet_lematizer.lemmatize(</span><span style="font-size: 9pt; line-height: 1.45;">'boxes'</span><span style="font-size: 9pt; line-height: 1.45;">))   <span style="font-size: 9pt; line-height: 1.45;">默认按照名词处理</span></span></font></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">wordnet_lematizer.lemmatize(</span><span style="font-size: 9pt; line-height: 1.45;">'are'</span><span style="font-size: 9pt; line-height: 1.45;">))   <span style="font-size: 9pt; line-height: 1.45;">默认按照名词处理</span></span></font></div></li><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">wordnet_lematizer.lemmatize(</span><span style="font-size: 9pt; line-height: 1.45;">'went'</span><span style="font-size: 9pt; line-height: 1.45;">))     <span style="font-size: 9pt; line-height: 1.45;">默认按照名词处理</span></span></font></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">print(wordnet_lematizer.lemmatize('are', pos='v'))    指明词性</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">print(wordnet_lematizer.lemmatize('went', pos='v'))     </span><span style="line-height: 1.45; font-size: 9pt;">指明词性</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">用pos指明词性可以更准确地进行lemma, lemmatize 默认为名词</span></div></li></ul></ul></ul></ul></ul><li><div><font style="font-size: 10pt;"><span style="line-height: 1.45; font-size: 10pt; font-weight: bold;">3.去除停用词</span></font></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">去除停用词的作用</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">为节省存储空间和提高搜索效率，NLP中会自动过滤掉某些字或词</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">停用词都是人工输入、非自动化生成的，形成停用词表</span></div></li></ul><li><div><span style="line-height: 1.45; font-size: 9pt;">停用词的种类</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">语言中的功能词，如the, is…</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">词汇词，通常是使用广泛的词，如want</span></div></li></ul><li><div><span style="font-size: 9pt;">停用词表</span></div></li><ul><li><div><a href="http://www.ranks.nl/stopwords" style="font-size: 9pt;">http://www.ranks.nl/stopwords</a></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">获取指定语言的停用歌词库</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">stopwords.words('language_name')</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">注意：所有停用词都是小写的</span></div></li></ul></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">去除停用词的方法</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">导入模块</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">from</span> <span style="font-size: 9pt; line-height: 1.45;">nltk.corpus</span> <span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">stopwords    </span><span style="font-size: 9pt; line-height: 1.45;"> 需要下载stopwords</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">获取未进行去除停用词的单词列表(已经进行了分词处理)</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">words = ['Python', 'is', 'a', 'widely', 'used', 'programming', 'language', '.']</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">对所有单词进行去除停用词</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">filtered_words = [word</span> <span style="font-size: 9pt; line-height: 1.45;">for</span> <span style="font-size: 9pt; line-height: 1.45;">word</span> <span style="font-size: 9pt; line-height: 1.45;">in</span> <span style="font-size: 9pt; line-height: 1.45;">words</span> <span style="font-size: 9pt; line-height: 1.45;">if</span> <span style="font-size: 9pt; line-height: 1.45;">word</span> <span style="font-size: 9pt; line-height: 1.45;">not</span> <span style="font-size: 9pt; line-height: 1.45;">in</span> <span style="font-size: 9pt; line-height: 1.45;">stopwords.words(</span><span style="font-size: 9pt; line-height: 1.45;">'english'</span><span style="font-size: 9pt; line-height: 1.45;">)]</span></div></li></ul><li><div><span style="line-height: 1.45; font-size: 9pt;">去除停用词之后的结果：</span><span style="line-height: 1.45; font-size: 9pt;">filtered_words</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">['Python', 'widely', 'used', 'programming', 'language', '.']</span></div></li></ul></ul></ul><li><div><font style="font-size: 10pt;"><span style="line-height: 13.6px; font-size: 10pt; font-weight: bold;">英文文本处理流程示例</span></font></div></li><ul><li><div><span style="font-size: 9pt;"><img src="/e_img/自然语言处理的流程_files/Image [2].png" type="image/png" data-filename="Image.png" width="553"/></span></div></li></ul></ul><div><font style="font-size: 14pt;"><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><span style="background-color: rgb(255, 250, 165); font-size: 14pt; color: rgb(50, 135, 18); font-weight: bold; line-height: 13.6px;-evernote-highlight:true;">jieba分词器的介绍</span></span></font></div><div><ul><li><div><font style="font-size: 10pt;"><span style="line-height: 13.6px; font-size: 10pt; font-weight: bold;">jieba分词器的介绍</span></font></div></li><ul><li><div><font style="font-size: 9pt;"><span style="line-height: 13.6px; font-size: 9pt; font-weight: bold;">jieba分词器的三种模式</span></font></div></li><ul><li><div><span style="font-size: 9pt;">全模式：把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义，适合情感分析；</span></div></li><li><div><span style="font-size: 9pt;">精确模式：试图将句子最精确地切开，适合文本分析，适合词频统计；</span></div></li><li><div><span style="font-size: 9pt;">搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; font-weight: bold;">安装方式</span></font></div></li><ul><li><div><span style="font-size: 9pt;">pip install jieba</span></div></li><li><div><span style="font-size: 9pt;">pip3 install jieba</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="line-height: 13.6px; font-size: 9pt; font-weight: bold;">导入jieba库的方法</span></font></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">import jieba </span></div></li></ul></ul><li><div><font style="font-size: 10pt;"><span style="line-height: 13.6px; font-size: 10pt; font-weight: bold;">使用jieba分词器进行分词</span></font></div></li><ul><li><div><span style="font-size: 9pt;"><img src="/e_img/自然语言处理的流程_files/Image [3].png" type="image/png" data-filename="Image.png" width="514"/></span></div></li></ul><li><div><font style="font-size: 10pt;"><span style="font-size: 10pt; font-weight: bold;">使用jieba分词器对词性词性进行标注</span></font></div></li><ul><li><div><font style="font-size: 9pt;"><span style="line-height: 1.45; font-size: 9pt; font-weight: bold;">导入jieba词性标注工具</span></font></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">import</span> <span style="font-size: 9pt; line-height: 1.45;">jieba.posseg</span> <span style="font-size: 9pt; line-height: 1.45;">as</span> <span style="font-size: 9pt; line-height: 1.45;">pseg</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="line-height: 13.6px; font-size: 9pt; font-weight: bold;">进行分词，并进行词性标注</span></font></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 1.45;">words = pseg.cut(</span><span style="font-size: 9pt; line-height: 1.45;">&quot;我爱北京天安门&quot;</span><span style="font-size: 9pt; line-height: 1.45;">)   返回的是分词后，有单词和词性构成的元组，并组成的列表</span></font></div></li></ul><li><div><font style="font-size: 9pt;"><span style="line-height: 13.6px; font-size: 9pt; font-weight: bold;">结果打印</span></font></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">for</span> <span style="font-size: 9pt; line-height: 1.45;">word, flag</span> <span style="font-size: 9pt; line-height: 1.45;">in</span> <span style="font-size: 9pt; line-height: 1.45;">words:</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 1.45;">print(</span><span style="font-size: 9pt; line-height: 1.45;">'%s %s'</span> <span style="font-size: 9pt; line-height: 1.45;">% (word, flag))</span></div></li></ul><li><div><span style="line-height: 1.45; font-size: 9pt;"> --&gt;</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">我 r</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">爱 v</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">北京 ns</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">天安门 ns</span></div></li></ul></ul></ul></ul></div><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><font style="font-size: 14pt;"><span style="background-color: rgb(255, 250, 165); font-size: 14pt; color: rgb(50, 135, 18); font-weight: bold; line-height: 13.6px;-evernote-highlight:true;">中文文本的处理流程</span></font></span></div><div><ul><li><div><font style="font-size: 10pt;"><span style="font-size: 10pt; font-weight: bold;">1.分词处理的方法</span></font></div></li><ul><li><div><span style="font-size: 9pt;">导入jieba分词器（需要先pip install jieba）</span></div></li><ul><li><div><span style="font-size: 9pt;">import jieba</span></div></li></ul><li><div><span style="font-size: 9pt;">准备需要分词的句子或者文章</span></div></li><ul><li><div><span style="font-size: 9pt;">text = '欢迎来到英雄联盟'</span></div></li></ul><li><div><span style="font-size: 9pt;">对文本进行分词</span></div></li><ul><li><div><span style="font-size: 9pt;">seg_list = jieba.cut(text, cut_all=True)</span></div></li><ul><li><div><span style="font-size: 9pt;">cut_all:  表示使用全模式来进行分词</span></div></li></ul></ul><li><div><span style="font-size: 9pt;">分词后的结果：seg_list</span></div></li><ul><li><div><span style="font-size: 9pt;">['欢迎', '来到', '英雄', '联盟', '英雄联盟']</span></div></li></ul></ul><li><div><font style="font-size: 10pt;"><span style="font-size: 10pt; font-weight: bold;">2.使用jieba分词器分词并标注词性--可选步骤（默认是精确模式）</span></font></div></li><ul><li><div><span style="font-size: 9pt;">导入jieba词性标注工具</span></div></li><ul><li><div><span style="font-size: 9pt;">import jieba.posseg as pseg</span></div></li></ul><li><div><span style="font-size: 9pt;">准备需要分词的句子或者文章</span></div></li><ul><li><div><span style="font-size: 9pt;">text = '欢迎来到英雄联盟'</span></div></li></ul><li><div><span style="font-size: 9pt;">进行分词，并进行词性标注</span></div></li><ul><li><div><span style="font-size: 9pt;">words_list = pseg.cut(text)   返回的是分词后，的单词和词性的对应结果</span></div></li></ul><li><div><span style="font-size: 9pt;">分词后的结果:words_list</span></div></li><ul><li><div><span style="font-size: 9pt;"><img src="/e_img/自然语言处理的流程_files/Image [4].png" type="image/png" data-filename="Image.png" width="747"/></span></div></li></ul></ul><li><div><font style="font-size: 10pt;"><span style="font-size: 10pt; line-height: 13.6px; font-weight: bold;">3.去除停用词</span></font></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">中文停用词表</span></div></li><ul><li><div><span style="line-height: 1.45; font-size: 9pt;">中文停用词库</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">哈工大停用词表</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">四川大学机器智能实验室停用词库</span></div></li><li><div><span style="line-height: 1.45; font-size: 9pt;">百度停用词列表</span></div></li></ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 13.6px;">准备分词后的列表</span></font></div></li><ul><li><div><span style="font-size: 9pt;">seg_list = ['我', '是' , '一个', '好人']</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">读取中文停用表</span></div></li><ul><li><div><span style="font-size: 9pt; line-height: 13.6px;">stopword_list = [line.rstrip() for line in</span> <span style="font-size: 9pt; line-height: 13.6px;">open('</span><span style="font-size: 9pt; line-height: 1.45;">哈工大停用词表.txt</span><span style="font-size: 9pt; line-height: 13.6px;">', 'r', encoding='utf-8')</span><span style="font-size: 9pt; line-height: 13.6px;">]</span></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">去停用词操作</span></div></li><ul><li><div><font style="font-size: 9pt;"><span style="font-size: 9pt; line-height: 13.6px;">filtered_list = [seg for seg in seg_list if seg not in <span style="font-size: 9pt; line-height: 13.6px;">stopword_list]</span></span></font></div></li></ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">取出后的结果: filtered_list</span></div></li><ul><li><div><span style="line-height: 13.6px; font-size: 9pt;">['好人']</span></div></li></ul></ul></ul></div></div><div><br/></div><div><br/></div></span>
</div></body></html>