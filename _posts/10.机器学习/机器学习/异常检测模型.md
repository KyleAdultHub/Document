---
title: 异常检测模型
date: "2018-12-14 22:13:00"
categories:
- 机器学习
- 机器学习
tags:
- 异常检测
- 高斯分布
toc: true
typora-root-url: ..\..\..
---

### 1.异常检测使用场景

#### 什么是异常检测

举个例子，比如在医院体检测量我们的血液中各种成分的含量，每一种含量都可以是一种特征，比如维生素，微量元素等含量。当测量的人很多，这样，就有了一个数据集，绘制成图标类似下面的样子：

![1544797296755](/img/1544797296755.png)

这里的每个点、每个叉，都是你的无标签数据。这样，异常检测问题可以定义如下：假设有一个人的特征变量为$x_test$ 。所谓的异常检测问题就是：我们希望知道知道这个人的测试指标是否正常范围，或者说，我们希望判断这个人进行进一步的检查。如果被检查的人的各项指标都在正常范围内，那么我们可以判断该人的体检接口属于正常，而不需要进一步的检查。

给定数据集$x^{(1)}, x^{(2)}, ....,x^{(m)}$ ，我们假使数据集是正常的，我们希望知道新的数据 $x_{test}$ 是不是异常的，即这个测
试数据不属于该组数据的几率如何。我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性 p(x) , 综上可以定义**异常检测**， 就是通过判根据测试数据和所有测试集的关系来判断其正常(或异常)的概率。

![1544797824366](/img/1544797824366.png)

上图中，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。这种方法称为**密度估计**，就是异常检测的核心思想，表达如下：

​                                                                     If $\quad p ( x ) \left\{ \begin{array} { l l } { < \varepsilon } & { \text { anomaly } } \\ { > = \varepsilon } & { \text { normal } } \end{array} \right.$

#### 异常检测的例子

1. 异常检测主要用来识别欺骗。例如在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登录一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户。
2. 服务器集群检测，特征可能包含：内存使用情况，被访问的磁盘数量，CPU的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是不是有可能出错了。

### 2.高斯分布

一般自然界产生的数据，我们通常认为会符合高斯分布，其表达方式为: $x \sim N \left( \mu , \sigma ^ { 2 } \right)$ , 则其高绿密度函数为: $p \left( x , \mu , \sigma ^ { 2 } \right) = \frac { 1 } { \sqrt { 2 \pi } \sigma } \exp \left( - \frac { ( x - \mu ) ^ { 2 } } { 2 \sigma ^ { 2 } } \right)$ , 所以我们可以利用已有的数据来预测总体中的u 和 σ2， 计算方法如下:

$\mu = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } x ^ { ( i ) }$    ;    $\sigma ^ { 2 } = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \left( x ^ { ( i ) } - \mu \right) ^ { 2 }$

![1544798530401](/img/1544798530401.png)

### 3.异常检测算法

#### 模型构建步骤

开始总结使用高斯分布的异常检测算法

**异常检测算法:**

1. 对于给定的数据集$x ^ { ( 1 ) } , x ^ { ( 2 ) } , \dots , x ^ { ( m ) }$， 计算高斯分布的u和σ2的估计值。

   ​			$\mu _ { j } = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } x _ { j } ^ { ( i ) }$
   ​			$\sigma _ { j } ^ { 2 } = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \left( x _ { j } ^ { ( i ) } - \mu _ { j } \right) ^ { 2 }$

2. 推导出对应的高斯分布后， 测试对应测试实例的正常概率p(x);

   ​		$p ( x ) = \prod _ { j = 1 } ^ { n } p \left( x _ { j } ; \mu _ { j } , \sigma _ { j } ^ { 2 } \right) = \prod _ { j = 1 } ^ { 1 } \frac { 1 } { \sqrt { 2 \pi } \sigma _ { j } } \exp \left( - \frac { \left( x _ { j } - \mu _ { j } \right) ^ { 2 } } { 2 \sigma _ { j } ^ { 2 } } \right)$

3. 选择一个$\varepsilon$ ， $p(x) = \varepsilon$ 作为判定边界，当$p ( x ) < \varepsilon$ 时， 测试实例为异常；

![1544799259012](/img/1544799259012.png)

#### 异常检测系统开发

异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量 y 的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。当我们开发一个异常检测系统时，我们从带标记（异常或正常）的数据着手，我们从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。

**构建步骤**

1. 将数据集划分成训练集，交叉检验集， 和测试集；
2. 进行模型构建
3. 尝试使用不同的 $\varepsilon$ 作为阈值，并预测数据是否异常，根据F1值或者查准率与查全率比例来选择$\varepsilon$
4. 选出 $\varepsilon$ 后，针对测试集进行预测，计算异常检验系统的 值，或者查准率与查全率之比

### 4. 异常检测和监督学习的对比

![1544800069985](/img/1544800069985.png)

总结： 当我们的数据集正负分类数量级差不多的时候，并且正负分类都有对应的标签的时候选择监督学习； 反之当我们有大量的数据，数据的正样本特别少， 可以使用异常检测；

### 5.特征选择

**特征转换**

异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布，例如使用对数函数：$x = \log ( x + c )$ ，其中 c 为非负常数； 或者 $x = x ^ { c }$  ，c 为 0-1 之间的一个分数，等方法。(编者注：在python中，通常用 np.log1p() 函数，log1p 就是 log(x + 1)，可以避免出现负数结果，反向函数就是 np.expm1() )

![1544800759437](/img/1544800759437.png)

**异常检测结果分析**

一个常见的问题是一些异常的数据可能也会有较高的 p(x) 值，因而被算法认为是正常的。这种情况下误差分析能够帮助我们，我们可以分析那些被算法错误预测为正常的数据，观察能否找出一些问题。我们可能能从问题中发现我们需要增加一些新的特征，增加这些新特征后获得的新算法能够帮助我们更好地进行异常检测。

![1544800925929](/img/1544800925929.png)

我们通常可以通过将一些相关的特征进行组合，来获得一些新的更好的特征（异常数据的该特征值异常地大或小），例如，在检测数据中心的计算机状况的例子中，我们可以用CPU负载与网络通信量的比例作为一个新的特征，如果该值异常地大，便有可能意味着该服务器是陷入了一些问题中。

### 6.多元高斯分布

比如我们的数据集的特征是两个相关的特征，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。

下图中是两个相关特征，洋红色的线（根据ε的不同其范围可大可小）是一般的高斯分布模型获得的判定边界，很明显绿色的X所代表的数据点很可能是异常值，但是其 p(x) 值却仍然在正常范围内。多元高斯分布将创建像图中蓝色曲线所示的判定边界。

![1544801259238](/img/1544801259238.png)

在一般的高斯分布模型中，我们计算 p(x) 的方法是： 通过分别计算每个特征对应的几率然后将其累乘起来，在多元高斯分布模型中，我们将构建特征的**协方差矩阵**，用所有的特征一起来计算 p(x) 。

**多元高斯分布算法步骤:**

1. 计算所有特征的平均值，再计算**协方差矩阵**；

   ​	           $\mu = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } x ^ { ( i ) }$

   ​		  $\Sigma = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \left( x ^ { ( i ) } - \mu \right) \left( x ^ { ( i ) } - \mu \right) ^ { T } = \frac { 1 } { m } ( X - \mu ) ^ { T } ( X - \mu )$

2. 计算高斯分布p(x)

   ​		 $p ( x ) = \frac { 1 } { ( 2 \pi ) ^ { \frac { n } { 2 } } | \Sigma | ^ { \frac { 1 } { 2 } } } \exp \left( - \frac { 1 } { 2 } ( x - \mu ) ^ { T } \Sigma ^ { - 1 } ( x - \mu ) \right)$

   ​		注: $\Sigma$是定矩阵，在 Octave 中用 det(sigma) 计算， $\Sigma ^ { - 1 }$是逆矩阵

3. 选择一个$\varepsilon$ ， $p(x) = \varepsilon$ 作为判定边界，当$p ( x ) < \varepsilon$ 时， 测试实例为异常；

**协方差矩阵对模型的影响**

![1544801877924](/img/1544801877924.png)

当从左下到右上的对角线上的数不为0的时候，表示特征之间存在相关性

上图是5个不同的模型，从左往右依次分析：

1. 是一个一般的高斯分布模型
2. 通过协方差矩阵，令特征1拥有较小的偏差，同时保持特征2的偏差
3. 通过协方差矩阵，令特征2拥有较大的偏差，同时保持特征1的偏差
4. 通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的正相关性

5. 通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的负相关性

**多远高斯模型作用**

![1544803318678](/img/1544803318678.png)

建立多远高斯分布模型后， 可以通过协方差，建立两个特征成正相关性的模型，这样就可以将上图绿色的点判断为异常点；

**多远高斯分布与普通高斯分布关系:**

可以证明的是，原本的高斯分布模型是多元高斯分布模型的一个子集，即像上图中的第1、2、3，3个例子所示，如果协方差矩阵只在对角线的单位上有非零的值时，即为原本的高斯分布模型了。

![1544802173806](/img/1544802173806.png)

原高斯分布模型被广泛使用着，如果特征之间在某种程度上存在相互关联的情况，我们可以通过构造新新特征的方法来捕捉这些相关性。

> 总结: 如果训练集不是太大，并且没有太多的特征，我们可以使用多元高斯分布模型。