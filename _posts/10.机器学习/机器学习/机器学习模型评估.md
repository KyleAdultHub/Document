---
title: 模型评估、优化、设计过程
date: "2018-11-24 19:19:00"
categories:
- 机器学习
- 机器学习
tags:
- 设计过程
- 模型评估
toc: true
typora-root-url: ..\..\..
---

## 1.机器学习模型的评估和选择

### 有啥方法能优化我们的模型

整理了一下优化模型时，经常做的一些操作，优化模型无外乎以下几种方法:

1. 获得更多的训练实例——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。
2. 尝试减少特征的数量
3. 尝试获得更多的特征
4. 尝试增加多项式特征
5. 尝试减少正则化程度
6. 尝试增加正则化程度

但是，也如我们所见，并不是任何模型都适用于这些优化方法，我们还需要对症下药，接下来可以看一下怎么确定，我们的模型需要什么**优化服务**

<!-- more -->

### 模型过拟合的判断

![1543045466595](/img/1543045466595.png)

当我们确定学习算法的参数的时候，我们考虑的是选择参量来使训练误差最小化，有人认为得到一个非常小的训练误差一定是一件好事，但我们已经知道，仅仅是因为这个假设具有很小的训练误差，并不能说明它就一定是一个好的假设函数。此时很可能模型已经产生了过拟合。

为了检验算法是否过拟合，我们将数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再分成训练集和测试集。

![1543045796477](/img/1543045796477.png)

测试集评估在通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差：

1. 对于线性回归模型，我们利用测试集数据计算代价函数 **J**

2. 对于逻辑回归模型，我们除了可以利用测试数据集来计算代价函数外还可以计算误分类比率

   ![1543046614286](/img/1543046614286.png)

### 模型的选择和交叉验证集

当我们的使用多项式模型的时候，经常会不确定多项式的项数该如何确定，下面是一种比较简单的处理思路:

假设我们要在10个不同次数的二项式模型之间进行选择：

​		![1543046781735](/img/1543046781735.png)

显然越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能适应我们的测试集或者推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。

选择模型的方法：使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集

![1543046920483](/img/1543046920483.png)

1. 使用训练集训练出10个模型

2. 用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）

3. 选取代价函数值最小的模型

4. 用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）Train/validation/test error

   **Training error:**
   $J{train}(\theta) = \frac{1}{2m}\sum\limits{i=1}{m}(h_{\theta}(x{(i)})-y{(i)})2$
   **Cross Validation error:**
   $J{cv}(\theta) = \frac{1}{2m{cv}}\sum\limits{i=1}^{m}(h{\theta}(x{(i)}_{cv})-y{(i)}_{cv})^2$
   **Test error:**
   $J{test}(\theta)=\frac{1}{2m{test}}\sum\limits{i=1}^{m{test}}(h{\theta}(x^{(i)}{cv})-y{(i)}_{cv})2​$

### 模型的偏差和方差

#### 诊断偏差和方差

当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？

其实是一个很有效的指示器，指引着可以改进算法的最有效的方法和途径。在这段视频中，我想更深入地探讨一下有关偏差和方差的问题，希望你能对它们有一个更深入的理解，并且也能弄清楚怎样评价一个学习算法，能够判断一个算法是偏差还是方差有问题，因为这个问题对于弄清如何改进学习算法的效果非常重要，高偏差和高方差的问题基本上来说是欠拟合和过拟合的问题。

![1543048169732](/img/1543048169732.png)

我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：

![1543048300914](/img/1543048300914.png)

通过训练误差和交叉验证集误差判断偏差和方差问题，总结如下:

> 训练集误差和交叉验证集误差近似时：偏差/欠拟合
> 交叉验证集误差远大于训练集误差时：方差/过拟合

#### 正则化力度与偏差/方差

在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与刚才选择多项式模型次数类似的问题。

![1543048899675](/img/1543048899675.png)

我们选择一系列的想要测试的 λ 值，通常是 0-10之间的呈现2倍关系的值（如 0， 0.01， 0.01， 0.04， 0.08， 0.015， 0.032， 0.064， 1.28,  2.56,  5.12,  10共12个）。 我们同样把数据分为训练集、交叉验证集和测试集。

![1543049032194](/img/1543049032194.png)

选择正则化系数的方法为：

1. 使用训练集训练出12个不同程度正则化的模型
2. 用12个模型分别对交叉验证集计算的出交叉验证误差
3. 选择得出交叉验证误差最小的模型
4. 运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：

![1543049356556](/img/1543049356556.png)

> 当 λ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大
> 随着 λ 的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加

#### 通过学习曲线评估偏差和方差

学习曲线就是一种很好的工具，我经常使用学习曲线来判断某一个学习算法是否处于偏差、方差问题。学习曲线是学习算法的一个很好的合理检验（sanity check）。学习曲线是将训练集误差和交叉验证集误差作为训练集实例数量（m）的函数绘制的图表。

例如： 如果我们有100行数据，我们从1行数据开始，逐渐学习更多行的数据。思想是：当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据。

![1543049717914](/img/1543049717914.png)

![1543049729709](/img/1543049729709.png)

如何利用学习曲线识别高偏差/欠拟合：作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观

![1543050534124](/img/1543050534124.png)

也就是说在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。

如何利用学习曲线识别高方差/过拟合：假设我们使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。

![1543050657218](/img/1543050657218.png)

也就是说在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。

学习曲线的总结:

> 当Jtrain和Jcv都偏高的时候，处于高偏差(欠拟合)的情况，此时增加训练数据不会有更好的结果
>
> 当Jtrain偏低而Jcv偏高的时候，处于高方差(过拟合)的情况，此时增加训练数据往往会获得更好的训练结果

#### 神经网络的方差和偏差

![1543052413063](/img/1543052413063.png)

使用**较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合**，但计算代价较小使用**较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合**，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。

通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。

对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。

#### 解决高偏差和高方差的总结

**解决高方差问题:**

1. 获得更多的训练实例——解决高方差
2. 尝试减少特征的数量——解决高方差
3. 尝试增加正则化程度λ——解决高方差

**解决高偏差的问题**

1. 尝试获得更多的特征——解决高偏差
2. 尝试增加多项式特征——解决高偏差
3. 尝试减少正则化程度λ——解决高偏差

### 类偏斜的误差度量

#### 类偏斜和查准率查全率的介绍

类偏斜情况表现为我们的训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例， 这时候很难用一般的误差度量方法来度量其真实的误差。

例如我们希望用算法来预测癌症是否是恶性的，在我们的训练集中，只有0.5%的实例是恶性肿瘤。假设我们编写一个非学习而来的算法，在所有情况下都预测肿瘤是良性的，那么误差只有0.5%。然而我们通过训练而得到的神经网络算法却有1%的误差。这时，误差的大小是不能视为评判算法效果的依据的。 因为，下面将引入查准率和查全率的概念。

我们将算法预测的结果分成四种情况：

1. 正确肯定（True Positive,TP）：预测为真，实际为真
2. 正确否定（True Negative,TN）：预测为假，实际为假
3. 错误肯定（False Positive,FP）：预测为真，实际为假
4. 错误否定（False Negative,FN）：预测为假，实际为真

> **查准率（Precision）和查全率（Recall**）的公式为 ：
>
> 查准率=TP/(TP+FP)。例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。
>
> 查全率=TP/(TP+FN)。例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。

这样，对于我们刚才那个总是预测病人肿瘤为良性的算法，其查全率是0。

因此，可以看出用于度量偏斜类问题，查准率和查全率更能体现模型表现的好坏。

![1543054968076](/img/1543054968076.png)

#### 查准率和查全率之间的选择

在很多的应用中，我们希望能够保证查准率和召回率的相对平衡。

继续沿用刚才预测肿瘤性质的例子。假使，我们的算法输出的结果在0-1 之间，我们使用阀值0.5 来预测真和假。

![1543055405994](/img/1543055405994.png)

查准率(Precision)=TP/(TP+FP) 例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。

查全率(Recall)=TP/(TP+FN)例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。

如果我们希望只在非常确信的情况下预测为真（肿瘤为恶性），即我们希望更高的查准率，我们可以使用比0.5更大的阀值，如0.7，0.9。这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。

如果我们希望提高查全率，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，我们可以使用比0.5更小的阀值，如0.3。

我们可以将不同阀值情况下，查全率与查准率的关系绘制成图表，曲线的形状根据数据的不同而不同：

![1543055622819](/img/1543055622819.png)

我们希望有一个帮助我们选择这个阀值的方法。

一种方法是计算F1 值（F1 Score），其计算公式为：

$F_1Score：2{PR\over{P+R}}$

我们选择使得F1值最高的阀值, F1的想法就是尽量让查准率和查全率都不会太小。

## 2.机器学习系统的设计

### 机器学习系统设计思路

以一个垃圾邮件分类器算法为例

为了解决这样一个问题，我们首先要做的决定是如何选择并表达特征向量。我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得我们的特征向量（出现为1，不出现为0），尺寸为100×1。

为了构建这个分类器算法，我们可以做很多事，例如：

1. 收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本
2. 基于邮件的路由信息开发一系列复杂的特征
3. 基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理
4. 为探测刻意的拼写错误（把watch 写成w4tch）开发复杂的算法

### 误差分析

**设计机器学习系统的首要任务**

当设计一个模型的时候， 最好的方法是快速的将最简单版本的算法实现，一旦做完，你可以画出学习曲线，通过画出学习曲线，以及检验误差，来找出你的算法是否有高偏差和高方差的问题，或者别的问题。在这样分析之后，再来决定用更多的数据训练，或者加入更多的特征变量是否有用。

这么做的原因是：因为通常你并不能提前知道你是否需要复杂的特征变量，或者你是否需要更多的数据，还是别的什么。提前知道你应该做什么，是非常难的，因为你缺少证据，缺少学习曲线。因此，你很难知道你应该把时间花在什么地方来提高算法的表现。但是当你实践一个非常简单即便不完美的方法时，你可以通过画出学习曲线来做出进一步的选择。你可以用这种方式来避免一种电脑编程里的过早优化问题，这种理念是：我们必须用证据来领导我们的决策，怎样分配自己的时间来优化算法，而不是仅仅凭直觉，凭直觉得出的东西一般总是错误的。

除了画出学习曲线之外，一件非常有用的事是误差分析。比如在构造垃圾邮件分类器时，可以看一看我的交叉验证数据集，然后亲自看一看哪些邮件被算法错误地分类。因此，通过这些被算法错误分类的垃圾邮件与非垃圾邮件，你可以发现某些系统性的规律：什么类型的邮件总是被错误分类。经常地这样做之后，这个过程能启发你构造新的特征变量，或者告诉你：现在这个系统的短处，然后启发你如何去提高它。

**构建一个学习算法的推荐方法为：**

1. 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法
2. 绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择
3. 进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的实例，看看这些实例是否有某种系统化的趋势

**举个误差分析的栗子:**

以我们的垃圾邮件过滤器为例，误差分析要做的既是检验交叉验证集中我们的算法产生错误预测的所有邮件，看：

1. 是否能将这些邮件按照类分组。例如医药品垃圾邮件，仿冒品垃圾邮件或者密码窃取邮件等。然后看分类器对哪一组邮件的预测误差最大，并着手优化。

2. 发现是否缺少某些特征，记下这些特征出现的次数。
例如记录下错误拼写出现了多少次，异常的邮件路由情况出现了多少次等等，然后从出现次数最多的情况开始着手优化。

**误差分析需要交叉验证来验证**

误差分析并不总能帮助我们判断应该采取怎样的行动。有时我们需要尝试不同的模型，然后进行比较，在模型比较时，用数值来判断哪一个模型更好更有效，通常我们是看交叉验证集的误差。

在我们的垃圾邮件分类器例子中，对于“我们是否应该将discount/discounts/discounted/discounting处理成同一个词？”如果这样做可以改善我们算法，我们会采用一些截词软件。误差分析不能帮助我们做出这类判断，我们只能尝试采用和不采用截词软件这两种不同方案，然后根据数值检验的结果来判断哪一种更好。

**不要用测试集来做交叉验证**

因此，当你在构造学习算法的时候，你总是会去尝试很多新的想法，实现出很多版本的学习算法，如果每一次你实践新想法的时候，你都要手动地检测这些例子，去看看是表现差还是表现好，那么这很难让你做出决定。到底是否使用词干提取，是否区分大小写。但是通过一个量化的数值评估，你可以看看这个数字，误差是变大还是变小了。你可以通过它更快地实践你的新想法，它基本上非常直观地告诉你：你的想法是提高了算法表现，还是让它变得更坏，这会大大提高你实践算法时的速度。所以我强烈推荐在交叉验证集上来实施误差分析，而不是在测试集上。但是，还是有一些人会在测试集上来做误差分析。即使这从数学上讲是不合适的。所以我还是推荐你在交叉验证向量上来做误差分析。

**总结:**

当你在研究一个新的机器学习问题时，推荐你实现一个较为简单快速、即便不是那么完美的算法。目前大家经常干的事情是：花费大量的时间在构造算法上，构造他们以为的简单的方法。因此，不要担心你的算法太简单，或者太不完美，而是尽可能快地实现你的算法。当你有了初始的实现之后，它会变成一个非常有力的工具，来帮助你决定下一步的做法。因为我们可以先看看算法造成的错误，通过误差分析，来看看他犯了什么错，然后来决定优化的方式。

另一件事是：假设你有了一个快速而不完美的算法实现，又有一个数值的评估数据，这会帮助你尝试新的想法，快速地发现你尝试的这些想法是否能够提高算法的表现，从而你会更快地做出决定，在算法中放弃什么，吸收什么误差分析可以帮助我们系统化地选择该做什么。