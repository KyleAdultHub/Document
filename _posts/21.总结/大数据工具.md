---
title: 大数据工具
date: "2020-04-24 14:23:11"
categories:
- 总结
tags:
- 总结
toc: true
typora-root-url: ..\..\..
---

## Zookeeper

### Zookeeper选举机制(全新集群)

假设有五台服务器组成的zookeeper集群,它们的id从1-5,同时它们都是最新启动的,也就是没有历史数据,在存放数据量这一点上,都是一样的.假设这些服务器依序启动；

1. 服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态

2. 服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态.

3. 服务器3启动,根据前面的理论分析,服务器3成为服务器1,2,3中的老大,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的leader.

4. 服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能接收当小弟的命了.
服务器5启动,同4一样,当小弟.

### Zookeeper选举机制(运行中集群)

运行中集群的选举机制需要加入数据id、leader id和逻辑时钟的概念。

数据id：数据新的id就大，数据每次更新都会更新id。

Leader id：就是我们配置的myid中的值，每个机器一个。

逻辑时钟：这个值从0开始递增,每次选举对应一个值,也就是说: 如果在同一次选举中,那么这个值应该是一致的 ; 逻辑时钟值越大,说明这一次选举leader的进程更新.

选举的标准就变成：

​ 1、逻辑时钟小的选举结果被忽略，重新投票

​ 2、统一逻辑时钟后，数据id大的胜出

​ 3、数据id相同的情况下，leader id大的胜出

### zookeeper 节点类型

znode的两种类型

短暂(ephemeral) : 客户端断开后节点自动删除，节点不能有子节点
持久(persistent)：客户端断开后不删除节点
znode四种目录形式(默认persistent)

persistent : 持久节点
persistent_sequential: 持久序列节点，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护(例: /test0000000019)，
ephemeral: 短暂节点
ephemera_sequential: 短暂序列节点
序列节点的作用

在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序

## Flume

### Flume 结构

![1587722046762](/img/1587722046762.png)

## azkaban

### azkaban 结构

1. azkaban web
2. azkaban executor
3. azkaban job (job 之间可以有依赖关系)

## Sqoop

### Sqoop 的工作机制

1. 将导入或导出命令翻译成mapreduce程序来实现
2. 在翻译出的mapreduce中主要是对inputformat和outputformat进行定制
3. 运行要依赖java 和hadoop运行环境

### Sqoop 从关系型数据库导入到HDFS

命令: sqoop import --connect jdbc:mysql://xxxxxxx/hivemeta2db --username root --password password --table sds
默认导出数据到/user/user.name/{tablename}, 可以通过 --tartget-dir 设置导出到hdfs文件系统的位置, 如果想要将所有表导出到hdfs 可以使用 import-all-tables 命令

参数解释:
- --m   设置并行任务数量, 即map数量
- --columns参数， 可以指定导出的字段，用,隔开字段名称
- --as-sequencefile   将文件导出为sequencefile 格式
- --class-name   为sequencefile 类文件指定类命名
  – --fields-terminated-by,--lines-terminated-by,--optionally-enclosed-by   指定分隔符，换行符，文件结束符
- --where  指定查询条件
- --hive-import: 导入到hive中

### Sqoop 从HDFS导出到关系型数据库

命令: sqoop export --connect jdbc:mysql://192.168.81.176/sqoop --username root -password passwd --table sds --export-dir /user/guojian/sds

## Hbase

### Hbase 介绍

Hbase 是一个高可靠性、高性能、面向列可伸缩的分布式存储系统

HBASE的目标是存储并处理大型的数据，更具体来说是仅需使用普通的硬件配置，就能够处理由成千上万的行和列所组成的大型数据。

### Hbase 与传统数据库的对比

 **传统数据库的问题**

1）数据量很大的时候无法存储

2）没有很好的备份机制

3）数据达到一定数量开始缓慢，很大的话基本无法支撑

**hbase的优势**

1）线性扩展，随着数据量增多可以通过节点扩展进行支撑(易扩展)

2）数据存储在hdfs上，备份机制健全(HDFS方便备份)

3）通过zookeeper协调查找数据，访问速度快。(数据搜索通过zookeeper，查询速度快)

### Hbase集群中的角色

1. 一个或者多个主节点，Hmaster
   - 管理用户对Table表的增、删、改、查操作；
   - 管理HRegion服务器的负载均衡，调整HRegion分布；
   - 在HRegion分裂后，负责新HRegion的分配；
   - 在HRegion服务器停机后，负责失效HRegion服务器上的HRegion迁移。

2. 多个从节点，HregionServer
   - 表的增删改查数据。
   - 和hdfs交互，存取数据。

### zookeeper 在hbase 中的作用

1. 保存Hmaster的地址和backup-master地址
2. 保存表-ROOT的地址 (hbase默认的根表，检索表)
3. HregionServer列表

### Hbase 的数据模型

1. rowkey

   与nosql数据库们一样,row key是用来检索记录的主键。

   row key保存为字节数组， 存储时，按照row key的字典序排序存储，设计key时要充分利用这一个特性。

   访问HBASE table中的行，只有三种方式：

   1）通过单个row key访问

   2）通过row key的range（正则）

   3）全表扫描

2. 列簇

   Hbase 中的每个列，多归属于某一个列簇。

   列簇是表的schema的一部分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如 courses:history，courses:math都属于courses 这个列族。

3. cell

   由{row key, columnFamily, version} 唯一确定的单元。cell中 的数据是没有类型的，全部是字节码形式存贮。

4. 时间戳

   Hbase中通过rowkey和columns确定的为一个存储单元称为cell。

   每个cell都保存着同一份数据的多个版本，版本可以通过时间戳来索引。

   为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，HBASE提供 了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段 时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。

### 数据模型示意图

![1587882214146](/img/1587882214146.png)

### 常用命令

创建表:  create 表名, 列簇1, 列簇2

查看所有表:  list

添加数据:  put 表名,  rowkey,  列簇: 列,  值

查看rowkey:   get  表名,  rowkey

查看列簇:  get 表名,  rowkey, 列簇

查看列: get  表名,  rowkey,  列簇: 列

### 存储结构

Zookeeper
​    - 	HegineServer
​           - .meta
​       - Hegine
​           - Store
​             - StoreFile
​           - MemStore
​           - HLog

### Hbase读流程

ZooKeeper---meta--regionserver--region--memstore--storefile

1、 通过zookeeper的-ROOT-  找到表 .META. 对应的hregionserver。

2、通过META表rowkey，表名等信息找到数据对应的regine。

3、通过zookerpeer 的信息找到对应的regioneserver。

4、连接到对应regineserver上的regine。

5、先从Memstore找数据，如果没有，再到StoreFile上读

6、 数据块会缓存

### Hbase 写流程

1、 通过zookeeper的-ROOT-  找到表 .META. 对应的hregionserver。

2、通过META表rowkey，表名等信息找到数据对应的regine。

3、通过zookerpeer 的信息找到对应的regioneserver。

4、 hregionserver将数据写到hlog（write ahead log）。为了数据的持久化和恢复。

5、 hregionserver将数据写到内存（memstore）

6、当memstore达到阈值(64M)，将内存中数据写入到storefile，并删除内存，并清空HLOG做标记点;  当storefile数量达到4块的时候, hmaster将数据加载到本地进行合并，如果合并的数据超过256M，会对块进行拆分，分给不同的hregionserver；

7、 反馈client写成功。

## Kafka

### kafka 相对传统技术的优势

- 快速:单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作。

- 可伸缩:在一组机器上对数据进行分区和简化，以支持更大的数据

- 持久:消息是持久性的，并在集群中进行复制，以防止数据丢失。

- 设计:它提供了容错保证和持久性

### Kafka 使用zookeeper 的作用

- Zookeeper主要用于在集群中不同节点之间进行通信
- 在Kafka中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取
- 除此之外，它还执行其他活动，如: leader检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。

### 解释Kafka的用户如何消费信息?

在Kafka中传递消息是通过使用sendfile API完成的。它支持将字节从套接口转移到磁盘，通过内核空间保存副本，并在内核用户之间调用内核。

### 解释如何提高远程用户的吞吐量?

如果用户位于与broker不同的数据中心，则可能需要调优套接口缓冲区大小，以对长网络延迟进行摊销。

### 解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息?

在数据中，为了精确地获得Kafka的消息，你必须遵循两件事: 在数据消耗期间避免重复，在数据生产过程中避免重复。

这里有两种方法，可以在数据生成时准确地获得一个语义:

- 每个分区使用一个单独的写入器，每当你发现一个网络错误，检查该分区中的最后一条消息，以查看您的最后一次写入是否成功
- 在消息中包含一个主键(UUID或其他)，并在用户中进行反复制

### Kafka为什么需要复制?

Kafka的信息复制确保了任何已发布的消息不会丢失，并且可以在机器错误、程序错误或更常见些的软件升级中使用。

